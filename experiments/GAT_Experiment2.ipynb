{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb101fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chand\\anaconda3\\envs\\AllPackages\\Lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "c:\\Users\\chand\\anaconda3\\envs\\AllPackages\\Lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\chand\\anaconda3\\envs\\AllPackages\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Block 1: imports & seeds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f91fdace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080, 5) 3192 anomaly minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sleep_quality</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>cardio_stability</th>\n",
       "      <th>pulmonary_efficiency</th>\n",
       "      <th>cognitive_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:00:00</th>\n",
       "      <td>0.755708</td>\n",
       "      <td>0.205395</td>\n",
       "      <td>0.830908</td>\n",
       "      <td>0.767178</td>\n",
       "      <td>0.510991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:01:00</th>\n",
       "      <td>0.659859</td>\n",
       "      <td>0.246476</td>\n",
       "      <td>0.844178</td>\n",
       "      <td>0.792851</td>\n",
       "      <td>0.417215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:02:00</th>\n",
       "      <td>0.706531</td>\n",
       "      <td>0.238954</td>\n",
       "      <td>0.868644</td>\n",
       "      <td>0.811848</td>\n",
       "      <td>0.416396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:03:00</th>\n",
       "      <td>0.744998</td>\n",
       "      <td>0.281297</td>\n",
       "      <td>0.838533</td>\n",
       "      <td>0.839644</td>\n",
       "      <td>0.434464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 00:04:00</th>\n",
       "      <td>0.714757</td>\n",
       "      <td>0.273863</td>\n",
       "      <td>0.833889</td>\n",
       "      <td>0.812706</td>\n",
       "      <td>0.471335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sleep_quality  stress_level  cardio_stability  \\\n",
       "2025-01-01 00:00:00       0.755708      0.205395          0.830908   \n",
       "2025-01-01 00:01:00       0.659859      0.246476          0.844178   \n",
       "2025-01-01 00:02:00       0.706531      0.238954          0.868644   \n",
       "2025-01-01 00:03:00       0.744998      0.281297          0.838533   \n",
       "2025-01-01 00:04:00       0.714757      0.273863          0.833889   \n",
       "\n",
       "                     pulmonary_efficiency  cognitive_load  \n",
       "2025-01-01 00:00:00              0.767178        0.510991  \n",
       "2025-01-01 00:01:00              0.792851        0.417215  \n",
       "2025-01-01 00:02:00              0.811848        0.416396  \n",
       "2025-01-01 00:03:00              0.839644        0.434464  \n",
       "2025-01-01 00:04:00              0.812706        0.471335  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block 2: create synthetic minute-level data (single person)\n",
    "def generate_synthetic_minute_data(days=7, signals=None, anomaly_spec=None, seed=SEED):\n",
    "    \"\"\"\n",
    "    Generates minute-by-minute multivariate signals for `days`.\n",
    "    signals: dict of base level and circadian influence multipliers, e.g.\n",
    "      {\"sleep_quality\": (0.8, -0.2), \"stress\": (0.2, 0.15), ...}\n",
    "    anomaly_spec: list of dicts describing injected anomalies:\n",
    "      [{\"type\":\"sleep_deprivation\",\"start_min\":1234,\"duration_min\": 60*48, \"magnitude\": -0.6}, ...]\n",
    "    Returns: df (DatetimeIndex), anomaly_label (binary array)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    minutes_per_day = 24 * 60\n",
    "    total_minutes = days * minutes_per_day\n",
    "    t = np.arange(total_minutes)\n",
    "    time_index = pd.date_range(\"2025-01-01\", periods=total_minutes, freq=\"1min\")\n",
    "\n",
    "    # default signals if none provided\n",
    "    if signals is None:\n",
    "        signals = {\n",
    "            \"sleep_quality\": (0.7, -0.25),\n",
    "            \"stress_level\": (0.25, 0.2),\n",
    "            \"cardio_stability\": (0.85, -0.05),\n",
    "            \"pulmonary_efficiency\": (0.8, 0.03),\n",
    "            \"cognitive_load\": (0.45, 0.18)\n",
    "        }\n",
    "\n",
    "    circadian = np.sin(2 * np.pi * t / minutes_per_day)  # daily periodicity\n",
    "\n",
    "    data = {}\n",
    "    for name, (base, circ_amp) in signals.items():\n",
    "        # base + circ_amp * circadian + small random walk + Gaussian noise\n",
    "        rw = np.cumsum(rng.normal(0, 0.0005, size=total_minutes))  # slow drift\n",
    "        signal = base + circ_amp * circadian + rw + rng.normal(0, 0.03, size=total_minutes)\n",
    "        data[name] = signal\n",
    "\n",
    "    anomaly_label = np.zeros(total_minutes, dtype=int)\n",
    "\n",
    "    # default anomaly_spec if none provided (simulate a 48h sleep deprivation and other events)\n",
    "    if anomaly_spec is None:\n",
    "        anomaly_spec = []\n",
    "        # sleep deprivation starting day 2 at 00:00 for 48 hours\n",
    "        sd_start = minutes_per_day * 1\n",
    "        anomaly_spec.append({\"type\":\"sleep_deprivation\", \"start_min\": sd_start, \"duration_min\": 60*48, \"magn\": -0.6})\n",
    "        # stress spikes: random short spikes\n",
    "        for i in range(6):\n",
    "            s = rng.randint(0, total_minutes-30)\n",
    "            anomaly_spec.append({\"type\":\"stress_spike\", \"start_min\": s, \"duration_min\": rng.randint(10,60), \"magn\": 0.6})\n",
    "        # pulmonary episodes\n",
    "        for i in range(3):\n",
    "            s = rng.randint(0, total_minutes-120)\n",
    "            anomaly_spec.append({\"type\":\"pulmonary_episode\",\"start_min\": s, \"duration_min\": rng.randint(30,180), \"magn\": -0.4})\n",
    "\n",
    "    # apply anomalies\n",
    "    for ev in anomaly_spec:\n",
    "        s = ev[\"start_min\"]\n",
    "        e = min(s + ev[\"duration_min\"], total_minutes)\n",
    "        typ = ev[\"type\"]\n",
    "        magn = ev.get(\"magn\", -0.4)\n",
    "        if typ == \"sleep_deprivation\":\n",
    "            # lower sleep_quality; increase stress gradually and reduce cardio after a lag\n",
    "            data[\"sleep_quality\"][s:e] += magn\n",
    "            # stress increases during and after\n",
    "            data[\"stress_level\"][s:e + 60*12] += 0.3  # some carryover 12 hours\n",
    "            # cardio affected after a delay of 6 hours\n",
    "            delay = 60*6\n",
    "            data[\"cardio_stability\"][s+delay:e+delay] += -0.15\n",
    "            anomaly_label[s:e] = 1\n",
    "        elif typ == \"stress_spike\":\n",
    "            data[\"stress_level\"][s:e] += magn\n",
    "            data[\"cognitive_load\"][s:e] += 0.2\n",
    "            anomaly_label[s:e] = 1\n",
    "        elif typ == \"pulmonary_episode\":\n",
    "            data[\"pulmonary_efficiency\"][s:e] += magn\n",
    "            anomaly_label[s:e] = 1\n",
    "\n",
    "    # clip to 0-1 meaningful range\n",
    "    for k in data:\n",
    "        data[k] = np.clip(data[k], 0.0, 1.0)\n",
    "\n",
    "    df = pd.DataFrame(data, index=time_index)\n",
    "    return df, anomaly_label\n",
    "\n",
    "# quick test\n",
    "df, anomaly_label = generate_synthetic_minute_data(days=7)\n",
    "print(df.shape, anomaly_label.sum(), \"anomaly minutes\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65d9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: sliding window creation + directed edge construction functions\n",
    "from scipy.signal import correlate\n",
    "\n",
    "def sliding_windows(df: pd.DataFrame, window_minutes=60*24, stride_minutes=60*6):\n",
    "    \"\"\"\n",
    "    Create overlapping windows. Returns list of (node_time_matrix, start_idx)\n",
    "    node_time_matrix shape: (num_nodes, window_minutes)\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    start_idxs = []\n",
    "    n = len(df)\n",
    "    for start in range(0, n - window_minutes - 1, stride_minutes):\n",
    "        w = df.iloc[start:start+window_minutes].values.T.astype(np.float32)\n",
    "        windows.append(w)\n",
    "        start_idxs.append(start)\n",
    "    return windows, start_idxs\n",
    "\n",
    "def directed_edges_by_lag(node_ts: np.ndarray, max_lag:int=60, corr_threshold:float=0.25):\n",
    "    \"\"\"\n",
    "    node_ts: (num_nodes, window_size)\n",
    "    returns list of (src, dst, weight, lag) meaning src leads dst by `lag` minutes\n",
    "    Uses normalized cross-correlation; looks for positive lags where src leads dst.\n",
    "    \"\"\"\n",
    "    num_nodes, L = node_ts.shape\n",
    "    edges = []\n",
    "    for i in range(num_nodes):\n",
    "        xi = node_ts[i] - node_ts[i].mean()\n",
    "        sxi = xi.std() if xi.std() != 0 else 1e-6\n",
    "        for j in range(num_nodes):\n",
    "            if i == j: continue\n",
    "            xj = node_ts[j] - node_ts[j].mean()\n",
    "            sxj = xj.std() if xj.std() != 0 else 1e-6\n",
    "            # full cross-correlation\n",
    "            xc = correlate(xj, xi, mode='full')  # correlation of xi -> xj: positive lag means xi leads xj\n",
    "            lags = np.arange(-L+1, L)\n",
    "            mid = len(xc)//2\n",
    "            # we want positive lags (xi leads xj) up to max_lag\n",
    "            pos_region = xc[mid+1: mid+1+max_lag]\n",
    "            if pos_region.size == 0:\n",
    "                continue\n",
    "            best_idx = np.argmax(np.abs(pos_region))\n",
    "            best_val = pos_region[best_idx] / (L * sxi * sxj)\n",
    "            lag = best_idx + 1\n",
    "            if abs(best_val) >= corr_threshold:\n",
    "                edges.append((i, j, float(best_val), int(lag)))\n",
    "    return edges\n",
    "\n",
    "def granger_directed_edges(node_ts: np.ndarray, maxlag:int=10, p_threshold:float=0.05):\n",
    "    \"\"\"\n",
    "    Pairwise Granger causality on the window. node_ts shape (num_nodes, L).\n",
    "    Returns list of (src, dst, pval, best_lag) where src Granger-causes dst.\n",
    "    NOTE: this is heavier; use smaller maxlag if window is short.\n",
    "    \"\"\"\n",
    "    num_nodes, L = node_ts.shape\n",
    "    edges = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i==j: continue\n",
    "            # statsmodels expects shape (T, 2) as [target, cause]\n",
    "            data = np.vstack([node_ts[j], node_ts[i]]).T  # test whether i causes j\n",
    "            try:\n",
    "                res = grangercausalitytests(data, maxlag=maxlag, verbose=False)\n",
    "                # collect min pval across lags for ssr_ftest\n",
    "                pvals = [(lag, res[lag][0]['ssr_ftest'][1]) for lag in res]\n",
    "                best_lag, best_p = min(pvals, key=lambda x: x[1])\n",
    "                if best_p < p_threshold:\n",
    "                    edges.append((i, j, float(best_p), int(best_lag)))\n",
    "            except Exception:\n",
    "                # numerical issues sometimes; skip\n",
    "                continue\n",
    "    return edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad964c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows: 24\n",
      "Data(x=[5, 4], edge_index=[2, 20], edge_attr=[20, 3], node_names=[5])\n"
     ]
    }
   ],
   "source": [
    "# Block 4: create PyG Data objects; combine cross-corr & granger info into edge_attr\n",
    "def window_to_pyg(node_ts: np.ndarray, node_names: List[str],\n",
    "                  use_granger=False, corr_thresh=0.25, max_lag=60):\n",
    "    \"\"\"\n",
    "    node_ts: (num_nodes, window_size)\n",
    "    returns torch_geometric.data.Data with x (per-node features) and directed edge_index (2 x E)\n",
    "    and edge_attr tensor (E x 3) for (corr_weight, lag, granger_p) where granger_p may be np.nan\n",
    "    \"\"\"\n",
    "    num_nodes = node_ts.shape[0]\n",
    "    # summary node features (mean,std,last,slope)\n",
    "    means = node_ts.mean(axis=1)\n",
    "    stds = node_ts.std(axis=1)\n",
    "    last = node_ts[:, -1]\n",
    "    slopes = np.array([np.polyfit(np.arange(node_ts.shape[1]), node_ts[i], 1)[0] for i in range(num_nodes)])\n",
    "    x = np.stack([means, stds, last, slopes], axis=1)\n",
    "    # directed cross-correlation edges\n",
    "    corr_edges = directed_edges_by_lag(node_ts, max_lag=max_lag, corr_threshold=corr_thresh)\n",
    "    # optional granger\n",
    "    gr_edges = {}\n",
    "    if use_granger:\n",
    "        g = granger_directed_edges(node_ts, maxlag=min(10, node_ts.shape[1]//10), p_threshold=0.05)\n",
    "        for (src, dst, pval, lag) in g:\n",
    "            gr_edges[(src,dst)] = (pval, lag)\n",
    "    # build edge lists and attributes\n",
    "    if len(corr_edges) == 0:\n",
    "        # fallback to small chain if no directed corr\n",
    "        corr_edges = [(i, i+1, 0.1, 1) for i in range(num_nodes-1)]\n",
    "\n",
    "    edge_index = np.array([[e[0] for e in corr_edges], [e[1] for e in corr_edges]])\n",
    "    edge_attrs = []\n",
    "    for (src, dst, weight, lag) in corr_edges:\n",
    "        gr_p, gr_l = (np.nan, -1)\n",
    "        if (src,dst) in gr_edges:\n",
    "            gr_p, gr_l = gr_edges[(src,dst)]\n",
    "        edge_attrs.append([weight, float(lag), float(gr_p if not np.isnan(gr_p) else np.nan)])\n",
    "    import torch\n",
    "    data = Data(x=torch.tensor(x, dtype=torch.float),\n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "                edge_attr=torch.tensor(np.array(edge_attrs), dtype=torch.float))\n",
    "    # store node names for interpretability\n",
    "    data.node_names = node_names\n",
    "    return data\n",
    "\n",
    "# Example: create windows and one Data\n",
    "window_size = 60*24   # 1-day windows\n",
    "stride = 60*6         # every 6 hours\n",
    "node_names = df.columns.tolist()\n",
    "windows, starts = sliding_windows(df, window_minutes=window_size, stride_minutes=stride)\n",
    "print(\"Total windows:\", len(windows))\n",
    "sample_data = window_to_pyg(windows[0], node_names, use_granger=False)\n",
    "print(sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcfc1f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 23 pyg graphs; targets shape: torch.Size([23, 5])\n"
     ]
    }
   ],
   "source": [
    "# Block 5: prepare sequences of graphs and targets (per-node next-window mean)\n",
    "pyg_graphs = []\n",
    "targets = []\n",
    "window_start_idxs = starts\n",
    "\n",
    "for w in windows:\n",
    "    pyg_graphs.append(window_to_pyg(w, node_names, use_granger=False, corr_thresh=0.2, max_lag=180))\n",
    "# target = mean of next window (per-node)\n",
    "targets_list = []\n",
    "for i in range(len(windows)-1):\n",
    "    # we'll predict next window mean for window i -> i+1\n",
    "    nxt = windows[i+1].mean(axis=1)  # (num_nodes,)\n",
    "    targets_list.append(nxt)\n",
    "# last window has no next; drop last pyg_graph to align sizes\n",
    "pyg_graphs = pyg_graphs[:-1]\n",
    "n_windows = len(pyg_graphs)\n",
    "targets = torch.tensor(np.stack(targets_list, axis=0), dtype=torch.float)  # (n_windows, num_nodes)\n",
    "print(\"Prepared\", n_windows, \"pyg graphs; targets shape:\", targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e55651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6: model definition (same basic idea; uses edge_index as directed)\n",
    "class GATEncoder(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, heads=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_dim, hidden_dim, heads=heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_dim*heads, out_dim, heads=1, concat=False)\n",
    "        self.dropout = dropout\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x  # (num_nodes, out_dim)\n",
    "\n",
    "class TemporalGATPredictor(nn.Module):\n",
    "    def __init__(self, gat_in, gat_hidden, gat_out, lstm_hidden, num_nodes, seq_len):\n",
    "        super().__init__()\n",
    "        self.encoder = GATEncoder(gat_in, gat_hidden, gat_out)\n",
    "        self.seq_len = seq_len\n",
    "        self.num_nodes = num_nodes\n",
    "        self.gat_out = gat_out\n",
    "        self.lstm = nn.LSTM(input_size=gat_out * num_nodes, hidden_size=lstm_hidden, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden, num_nodes)\n",
    "    def forward(self, batch_graphs: List[Data]):\n",
    "        # encode each snapshot\n",
    "        encoded = []\n",
    "        for data in batch_graphs:\n",
    "            z = self.encoder(data.x, data.edge_index)  # (num_nodes, gat_out)\n",
    "            encoded.append(z.view(-1))\n",
    "        seq = torch.stack(encoded, dim=0).unsqueeze(0)  # shape (1, seq_len, num_nodes*gat_out)\n",
    "        out, _ = self.lstm(seq)\n",
    "        final = out[:, -1, :]\n",
    "        pred = torch.sigmoid(self.fc(final))\n",
    "        return pred.squeeze(0)  # (num_nodes,)\n",
    "\n",
    "# hyperparams\n",
    "gat_in = 4\n",
    "gat_hidden = 16\n",
    "gat_out = 8\n",
    "lstm_hidden = 64\n",
    "num_nodes = len(node_names)\n",
    "seq_len = 6\n",
    "\n",
    "model = TemporalGATPredictor(gat_in, gat_hidden, gat_out, lstm_hidden, num_nodes, seq_len)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ad95982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 train_loss=0.05729 val_loss=0.03742\n",
      "Epoch 05 train_loss=0.01046 val_loss=0.00258\n",
      "Epoch 10 train_loss=0.00992 val_loss=0.00306\n",
      "Epoch 15 train_loss=0.00977 val_loss=0.00241\n",
      "Epoch 20 train_loss=0.00977 val_loss=0.00291\n",
      "Epoch 25 train_loss=0.01037 val_loss=0.00388\n",
      "Training done. Best val loss: 0.0012999041937291622\n"
     ]
    }
   ],
   "source": [
    "# Block 7: train / val / test split & training loop\n",
    "n = n_windows\n",
    "idxs = list(range(0, n - seq_len))  # valid starting indices (predict i+seq_len)\n",
    "random.shuffle(idxs)\n",
    "train_frac, val_frac = 0.7, 0.15\n",
    "n_train = int(train_frac * len(idxs))\n",
    "n_val = int(val_frac * len(idxs))\n",
    "train_idx = idxs[:n_train]\n",
    "val_idx = idxs[n_train:n_train+n_val]\n",
    "test_idx = idxs[n_train+n_val:]\n",
    "\n",
    "def get_sequence(i):\n",
    "    # returns sequence list of Data objects of length seq_len, and target tensor\n",
    "    seq_datas = [pyg_graphs[j] for j in range(i, i + seq_len)]\n",
    "    target = targets[i + seq_len]  # (num_nodes,)\n",
    "    return seq_datas, target\n",
    "\n",
    "n_epochs = 25\n",
    "best_val = float('inf')\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    random.shuffle(train_idx)\n",
    "    for i in train_idx:\n",
    "        seq_datas, target = get_sequence(i)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(seq_datas)  # (num_nodes,)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_train = total_loss / max(1, len(train_idx))\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i in val_idx:\n",
    "            seq_datas, target = get_sequence(i)\n",
    "            pred = model(seq_datas)\n",
    "            val_loss += criterion(pred, target).item()\n",
    "    val_loss = val_loss / max(1, len(val_idx))\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:02d} train_loss={avg_train:.5f} val_loss={val_loss:.5f}\")\n",
    "\n",
    "# load best\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "print(\"Training done. Best val loss:\", best_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f06f2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 1.0 PR-AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Block 8: evaluate across test indices -> build anomaly scores per predicted window\n",
    "model.eval()\n",
    "scores = []\n",
    "true_labels = []\n",
    "window_centers = []\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in test_idx:\n",
    "        seq, target = get_sequence(i)\n",
    "        pred = model(seq).cpu().numpy()\n",
    "        mse = float(np.mean((pred - target.numpy())**2))\n",
    "        scores.append(mse)\n",
    "        preds.append(pred)\n",
    "        # window index of prediction is i + seq_len\n",
    "        true_labels.append(int(anomaly_label[window_start_idxs[i + seq_len]]))  # rough alignment\n",
    "        window_centers.append(window_start_idxs[i + seq_len])\n",
    "scores = np.array(scores)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "if len(np.unique(true_labels)) > 1:\n",
    "    roc = roc_auc_score(true_labels, scores)\n",
    "    pr = average_precision_score(true_labels, scores)\n",
    "else:\n",
    "    roc, pr = np.nan, np.nan\n",
    "print(\"ROC-AUC:\", roc, \"PR-AUC:\", pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24eec73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbation delta (pert - orig) per node: {'sleep_quality': -0.002771735191345215, 'stress_level': 0.0033150315284729004, 'cardio_stability': -0.003277719020843506, 'pulmonary_efficiency': -0.003799617290496826, 'cognitive_load': 0.0008999109268188477}\n",
      "Top affected nodes when perturbing sleep_quality: [('pulmonary_efficiency', 0.0037996173), ('stress_level', 0.0033150315), ('cardio_stability', 0.003277719)]\n"
     ]
    }
   ],
   "source": [
    "# Block 9: perturbation influence function to quantify downstream effect\n",
    "def perturb_and_measure(model, seq_datas, node_idx, perturbation=-0.3, which_snapshot=-1):\n",
    "    \"\"\"\n",
    "    Perturb node `node_idx` feature(s) in snapshot `which_snapshot` (default last)\n",
    "    Returns delta per-node: pred_pert - pred_orig\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    seq_p = copy.deepcopy(seq_datas)\n",
    "    # perturb mean/last/slope features for the node in the chosen snapshot\n",
    "    with torch.no_grad():\n",
    "        pred_orig = model(seq_datas).cpu().numpy()\n",
    "    # apply perturbation to all four features of that node in snapshot\n",
    "    seq_p[which_snapshot].x[node_idx] = seq_p[which_snapshot].x[node_idx] + perturbation\n",
    "    with torch.no_grad():\n",
    "        pred_pert = model(seq_p).cpu().numpy()\n",
    "    delta = pred_pert - pred_orig\n",
    "    return delta, pred_orig, pred_pert\n",
    "\n",
    "# Example: pick a detected anomaly window in test set and compute perturbation influence\n",
    "# Choose first test i where score high\n",
    "if len(test_idx) == 0:\n",
    "    print(\"No test indices\")\n",
    "else:\n",
    "    # pick worst scoring window\n",
    "    worst_idx_in_test = test_idx[np.argmax(scores)]\n",
    "    seq_datas, target = get_sequence(worst_idx_in_test)\n",
    "    # choose node 0 (sleep_quality) perturbation to see downstream effect\n",
    "    delta, orig, pert = perturb_and_measure(model, seq_datas, node_idx=0, perturbation=-0.4, which_snapshot=-1)\n",
    "    print(\"Perturbation delta (pert - orig) per node:\", {node_names[i]: float(delta[i]) for i in range(len(node_names))})\n",
    "    # brief narrative\n",
    "    affected = sorted([(node_names[i], abs(delta[i])) for i in range(len(node_names))], key=lambda x: x[1], reverse=True)\n",
    "    print(\"Top affected nodes when perturbing sleep_quality:\", affected[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49feed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed edges for snapshot (top):\n",
      "sleep_quality -> cognitive_load | weight=-0.933 | lag=24min | granger_p=None\n",
      "cognitive_load -> stress_level | weight=0.929 | lag=1min | granger_p=None\n",
      "stress_level -> cognitive_load | weight=0.928 | lag=1min | granger_p=None\n",
      "cognitive_load -> sleep_quality | weight=-0.927 | lag=5min | granger_p=None\n",
      "sleep_quality -> stress_level | weight=-0.863 | lag=55min | granger_p=None\n",
      "stress_level -> sleep_quality | weight=-0.844 | lag=1min | granger_p=None\n",
      "sleep_quality -> cardio_stability | weight=0.729 | lag=2min | granger_p=None\n",
      "cardio_stability -> sleep_quality | weight=0.727 | lag=8min | granger_p=None\n",
      "cardio_stability -> cognitive_load | weight=-0.702 | lag=9min | granger_p=None\n",
      "cognitive_load -> cardio_stability | weight=-0.693 | lag=2min | granger_p=None\n"
     ]
    }
   ],
   "source": [
    "# Block 10: show directed edges (cross-corr and granger p if present) for an example snapshot\n",
    "def edges_report(data: Data, node_names: List[str], top_k=10):\n",
    "    \"\"\"\n",
    "    data.edge_attr columns: [corr_weight, lag, granger_p (or nan)]\n",
    "    \"\"\"\n",
    "    ei = data.edge_index.cpu().numpy()\n",
    "    eattr = data.edge_attr.cpu().numpy()\n",
    "    edges = []\n",
    "    for k in range(ei.shape[1]):\n",
    "        src, dst = int(ei[0,k]), int(ei[1,k])\n",
    "        w, lag, gp = eattr[k]\n",
    "        edges.append((node_names[src], node_names[dst], float(w), int(lag), float(gp) if not np.isnan(gp) else None))\n",
    "    edges = sorted(edges, key=lambda x: abs(x[2]), reverse=True)\n",
    "    for e in edges[:top_k]:\n",
    "        print(f\"{e[0]} -> {e[1]} | weight={e[2]:.3f} | lag={e[3]}min | granger_p={e[4]}\")\n",
    "\n",
    "# show for the worst snapshot used above\n",
    "snap_idx = worst_idx_in_test + seq_len  # predicted window index corresponding\n",
    "snap_data = pyg_graphs[snap_idx]\n",
    "print(\"Directed edges for snapshot (top):\")\n",
    "edges_report(snap_data, node_names, top_k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "036de47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>src_idx</th>\n",
       "      <th>dst_idx</th>\n",
       "      <th>count</th>\n",
       "      <th>median_weight</th>\n",
       "      <th>median_lag_min</th>\n",
       "      <th>granger_p_median</th>\n",
       "      <th>weights_list</th>\n",
       "      <th>lags_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.929256</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.9477135539054871, 0.9017395377159119, 0.952...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stress_level</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.928015</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.9487643241882324, 0.9015536308288574, 0.952...</td>\n",
       "      <td>[8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.927903</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.9545643925666809, -0.8698533773422241, -0....</td>\n",
       "      <td>[4, 1, 1, 1, 1, 1, 24, 2, 23, 7, 178, 18, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.924469</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.9557874798774719, -0.8696070313453674, -0....</td>\n",
       "      <td>[1, 1, 8, 4, 18, 1, 5, 1, 1, 166, 11, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.869940</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.9655612707138062, -0.9609084725379944, -0....</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 55, 4, 54, 2, 55, 1, 4, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stress_level</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.860379</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.9666393399238586, -0.9603537321090698, -0....</td>\n",
       "      <td>[7, 1, 1, 1, 29, 1, 1, 1, 1, 108, 52, 1, 4, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.715931</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.770922064781189, 0.5661665201187134, 0.7286...</td>\n",
       "      <td>[6, 2, 1, 1, 180, 5, 8, 1, 1, 179, 1, 2, 109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.714787</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.7662836313247681, 0.5766874551773071, 0.767...</td>\n",
       "      <td>[1, 42, 82, 82, 178, 2, 2, 3, 23, 3, 3, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.696417</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.7451180219650269, -0.6690930724143982, -0....</td>\n",
       "      <td>[4, 1, 1, 1, 179, 1, 9, 2, 9, 1, 180, 179, 114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.693467</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.7437114119529724, -0.6740134954452515, -0....</td>\n",
       "      <td>[11, 24, 140, 179, 179, 2, 2, 2, 18, 2, 180, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.651056</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.7578170299530029, -0.5504528880119324, -0....</td>\n",
       "      <td>[14, 1, 1, 1, 180, 2, 47, 10, 43, 8, 180, 124,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stress_level</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.758777379989624, -0.5738000869750977, -0.7...</td>\n",
       "      <td>[19, 58, 124, 124, 4, 18, 1, 1, 1, 179, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.537711</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.5441463589668274, -0.588294267654419, -0.6...</td>\n",
       "      <td>[9, 2, 2, 2, 28, 28, 8, 2, 9, 69, 2, 9, 9, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.535893</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.5358934998512268, 0.6042319536209106, 0.645...</td>\n",
       "      <td>[11, 10, 11, 5, 10, 3, 2, 2, 4, 2, 7, 7, 7, 7,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.533685</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.5521436929702759, -0.5932676792144775, -0....</td>\n",
       "      <td>[48, 6, 5, 1, 2, 2, 8, 21, 5, 3, 1, 1, 12, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.528713</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.5473551750183105, 0.608403742313385, 0.6587...</td>\n",
       "      <td>[51, 1, 39, 1, 37, 1, 1, 1, 1, 1, 1, 1, 20, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.492210</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.5351166725158691, 0.5710274577140808, 0.652...</td>\n",
       "      <td>[5, 3, 3, 1, 9, 9, 4, 1, 3, 3, 9, 1, 32, 16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stress_level</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.491644</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.5497491955757141, 0.5741972327232361, 0.656...</td>\n",
       "      <td>[39, 4, 4, 4, 37, 2, 2, 2, 2, 2, 2, 2, 23, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.436273</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.4590439796447754, -0.480249285697937, -0.5...</td>\n",
       "      <td>[60, 5, 2, 6, 6, 6, 6, 25, 7, 172, 128, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.429223</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.4447994530200958, -0.4811718761920929, -0....</td>\n",
       "      <td>[16, 22, 44, 112, 4, 31, 10, 10, 18, 164, 4, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     src                   dst  src_idx  dst_idx  count  \\\n",
       "0         cognitive_load          stress_level        4        1     23   \n",
       "1           stress_level        cognitive_load        1        4     23   \n",
       "2          sleep_quality        cognitive_load        0        4     22   \n",
       "3         cognitive_load         sleep_quality        4        0     22   \n",
       "4          sleep_quality          stress_level        0        1     23   \n",
       "5           stress_level         sleep_quality        1        0     23   \n",
       "6       cardio_stability         sleep_quality        2        0     23   \n",
       "7          sleep_quality      cardio_stability        0        2     23   \n",
       "8       cardio_stability        cognitive_load        2        4     23   \n",
       "9         cognitive_load      cardio_stability        4        2     23   \n",
       "10      cardio_stability          stress_level        2        1     23   \n",
       "11          stress_level      cardio_stability        1        2     22   \n",
       "12  pulmonary_efficiency         sleep_quality        3        0     16   \n",
       "13  pulmonary_efficiency        cognitive_load        3        4     19   \n",
       "14         sleep_quality  pulmonary_efficiency        0        3     17   \n",
       "15        cognitive_load  pulmonary_efficiency        4        3     21   \n",
       "16  pulmonary_efficiency          stress_level        3        1     21   \n",
       "17          stress_level  pulmonary_efficiency        1        3     21   \n",
       "18      cardio_stability  pulmonary_efficiency        2        3     17   \n",
       "19  pulmonary_efficiency      cardio_stability        3        2     16   \n",
       "\n",
       "    median_weight  median_lag_min  granger_p_median  \\\n",
       "0        0.929256               1               NaN   \n",
       "1        0.928015               1               NaN   \n",
       "2       -0.927903               3               NaN   \n",
       "3       -0.924469               1               NaN   \n",
       "4       -0.869940               1               NaN   \n",
       "5       -0.860379               1               NaN   \n",
       "6        0.715931               3               NaN   \n",
       "7        0.714787               3               NaN   \n",
       "8       -0.696417               9               NaN   \n",
       "9       -0.693467               3               NaN   \n",
       "10      -0.651056              19               NaN   \n",
       "11      -0.644204               4               NaN   \n",
       "12      -0.537711               5               NaN   \n",
       "13       0.535893               7               NaN   \n",
       "14      -0.533685               5               NaN   \n",
       "15       0.528713               1               NaN   \n",
       "16       0.492210               3               NaN   \n",
       "17       0.491644               4               NaN   \n",
       "18      -0.436273               6               NaN   \n",
       "19      -0.429223              17               NaN   \n",
       "\n",
       "                                         weights_list  \\\n",
       "0   [0.9477135539054871, 0.9017395377159119, 0.952...   \n",
       "1   [0.9487643241882324, 0.9015536308288574, 0.952...   \n",
       "2   [-0.9545643925666809, -0.8698533773422241, -0....   \n",
       "3   [-0.9557874798774719, -0.8696070313453674, -0....   \n",
       "4   [-0.9655612707138062, -0.9609084725379944, -0....   \n",
       "5   [-0.9666393399238586, -0.9603537321090698, -0....   \n",
       "6   [0.770922064781189, 0.5661665201187134, 0.7286...   \n",
       "7   [0.7662836313247681, 0.5766874551773071, 0.767...   \n",
       "8   [-0.7451180219650269, -0.6690930724143982, -0....   \n",
       "9   [-0.7437114119529724, -0.6740134954452515, -0....   \n",
       "10  [-0.7578170299530029, -0.5504528880119324, -0....   \n",
       "11  [-0.758777379989624, -0.5738000869750977, -0.7...   \n",
       "12  [-0.5441463589668274, -0.588294267654419, -0.6...   \n",
       "13  [0.5358934998512268, 0.6042319536209106, 0.645...   \n",
       "14  [-0.5521436929702759, -0.5932676792144775, -0....   \n",
       "15  [0.5473551750183105, 0.608403742313385, 0.6587...   \n",
       "16  [0.5351166725158691, 0.5710274577140808, 0.652...   \n",
       "17  [0.5497491955757141, 0.5741972327232361, 0.656...   \n",
       "18  [-0.4590439796447754, -0.480249285697937, -0.5...   \n",
       "19  [-0.4447994530200958, -0.4811718761920929, -0....   \n",
       "\n",
       "                                            lags_list  \n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, ...  \n",
       "1   [8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, ...  \n",
       "2   [4, 1, 1, 1, 1, 1, 24, 2, 23, 7, 178, 18, 1, 1...  \n",
       "3   [1, 1, 8, 4, 18, 1, 5, 1, 1, 166, 11, 1, 1, 1,...  \n",
       "4   [1, 1, 1, 1, 1, 1, 55, 4, 54, 2, 55, 1, 4, 1, ...  \n",
       "5   [7, 1, 1, 1, 29, 1, 1, 1, 1, 108, 52, 1, 4, 1,...  \n",
       "6   [6, 2, 1, 1, 180, 5, 8, 1, 1, 179, 1, 2, 109, ...  \n",
       "7   [1, 42, 82, 82, 178, 2, 2, 3, 23, 3, 3, 1, 1, ...  \n",
       "8   [4, 1, 1, 1, 179, 1, 9, 2, 9, 1, 180, 179, 114...  \n",
       "9   [11, 24, 140, 179, 179, 2, 2, 2, 18, 2, 180, 2...  \n",
       "10  [14, 1, 1, 1, 180, 2, 47, 10, 43, 8, 180, 124,...  \n",
       "11  [19, 58, 124, 124, 4, 18, 1, 1, 1, 179, 1, 1, ...  \n",
       "12  [9, 2, 2, 2, 28, 28, 8, 2, 9, 69, 2, 9, 9, 2, ...  \n",
       "13  [11, 10, 11, 5, 10, 3, 2, 2, 4, 2, 7, 7, 7, 7,...  \n",
       "14  [48, 6, 5, 1, 2, 2, 8, 21, 5, 3, 1, 1, 12, 3, ...  \n",
       "15  [51, 1, 39, 1, 37, 1, 1, 1, 1, 1, 1, 1, 20, 1,...  \n",
       "16  [5, 3, 3, 1, 9, 9, 4, 1, 3, 3, 9, 1, 32, 16, 1...  \n",
       "17  [39, 4, 4, 4, 37, 2, 2, 2, 2, 2, 2, 2, 23, 2, ...  \n",
       "18  [60, 5, 2, 6, 6, 6, 6, 25, 7, 172, 128, 3, 4, ...  \n",
       "19  [16, 22, 44, 112, 4, 31, 10, 10, 18, 164, 4, 7...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block A: aggregate directed edges across all windows into a single DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def aggregate_directed_edges(pyg_graphs, node_names, min_occurrence=1):\n",
    "    \"\"\"\n",
    "    Collects directed edges (from each snapshot's edge_index & edge_attr),\n",
    "    aggregates weight (median), lag (median), and counts occurrences.\n",
    "    Returns DataFrame with columns: src, dst, count, median_weight, median_lag, granger_p_median (if present)\n",
    "    \"\"\"\n",
    "    edge_store = defaultdict(list)  # key: (src,dst) -> list of (weight, lag, gr_p)\n",
    "    for g in pyg_graphs:\n",
    "        if not hasattr(g, 'edge_index') or g.edge_index is None:\n",
    "            continue\n",
    "        ei = g.edge_index.cpu().numpy()\n",
    "        eattr = g.edge_attr.cpu().numpy() if hasattr(g, 'edge_attr') else None\n",
    "        for k in range(ei.shape[1]):\n",
    "            src, dst = int(ei[0,k]), int(ei[1,k])\n",
    "            if eattr is None:\n",
    "                weight, lag, gp = 0.0, -1, np.nan\n",
    "            else:\n",
    "                weight, lag, gp = float(eattr[k,0]), int(eattr[k,1]), float(eattr[k,2]) if not np.isnan(eattr[k,2]) else np.nan\n",
    "            edge_store[(src,dst)].append((weight, lag, gp))\n",
    "    rows = []\n",
    "    for (src,dst), vals in edge_store.items():\n",
    "        if len(vals) < min_occurrence:\n",
    "            continue\n",
    "        weights = np.array([v[0] for v in vals])\n",
    "        lags = np.array([v[1] for v in vals])\n",
    "        gps = np.array([v[2] for v in vals])\n",
    "        rows.append({\n",
    "            \"src\": node_names[src],\n",
    "            \"dst\": node_names[dst],\n",
    "            \"src_idx\": src,\n",
    "            \"dst_idx\": dst,\n",
    "            \"count\": len(vals),\n",
    "            \"median_weight\": float(np.median(weights)),\n",
    "            \"median_lag_min\": int(np.median(lags)),\n",
    "            \"granger_p_median\": float(np.nanmedian(gps) if not np.all(np.isnan(gps)) else np.nan),\n",
    "            \"weights_list\": weights,\n",
    "            \"lags_list\": lags\n",
    "        })\n",
    "    df_edges = pd.DataFrame(rows).sort_values(\"median_weight\", key=lambda s: s.abs(), ascending=False).reset_index(drop=True)\n",
    "    return df_edges\n",
    "\n",
    "# Example usage:\n",
    "global_edges_df = aggregate_directed_edges(pyg_graphs, node_names, min_occurrence=1)\n",
    "global_edges_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a186de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturb samples: 100%|██████████| 17/17 [00:01<00:00,  8.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_idx</th>\n",
       "      <th>dst_idx</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>mean_delta</th>\n",
       "      <th>mean_abs_delta</th>\n",
       "      <th>std_delta</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>-0.005285</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>-0.005251</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>-0.004757</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>-0.004447</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>-0.004372</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>-0.004347</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>-0.004180</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>-0.003795</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>-0.003738</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>-0.003590</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>-0.003311</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>-0.003249</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>-0.003110</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    src_idx  dst_idx                   src                   dst  mean_delta  \\\n",
       "0         2        3      cardio_stability  pulmonary_efficiency   -0.006202   \n",
       "1         2        1      cardio_stability          stress_level    0.005470   \n",
       "2         2        2      cardio_stability      cardio_stability   -0.005285   \n",
       "3         3        3  pulmonary_efficiency  pulmonary_efficiency   -0.005251   \n",
       "4         2        0      cardio_stability         sleep_quality   -0.004757   \n",
       "5         3        1  pulmonary_efficiency          stress_level    0.004680   \n",
       "6         3        2  pulmonary_efficiency      cardio_stability   -0.004537   \n",
       "7         0        3         sleep_quality  pulmonary_efficiency   -0.004447   \n",
       "8         3        0  pulmonary_efficiency         sleep_quality   -0.004372   \n",
       "9         4        3        cognitive_load  pulmonary_efficiency   -0.004347   \n",
       "10        1        3          stress_level  pulmonary_efficiency   -0.004180   \n",
       "11        0        1         sleep_quality          stress_level    0.003947   \n",
       "12        4        1        cognitive_load          stress_level    0.003845   \n",
       "13        0        2         sleep_quality      cardio_stability   -0.003795   \n",
       "14        4        2        cognitive_load      cardio_stability   -0.003738   \n",
       "15        1        1          stress_level          stress_level    0.003698   \n",
       "16        1        2          stress_level      cardio_stability   -0.003590   \n",
       "17        0        0         sleep_quality         sleep_quality   -0.003311   \n",
       "18        4        0        cognitive_load         sleep_quality   -0.003249   \n",
       "19        1        0          stress_level         sleep_quality   -0.003110   \n",
       "\n",
       "    mean_abs_delta  std_delta  count  \n",
       "0         0.006202   0.000877     17  \n",
       "1         0.005470   0.000745     17  \n",
       "2         0.005285   0.000744     17  \n",
       "3         0.005251   0.001675     17  \n",
       "4         0.004757   0.000673     17  \n",
       "5         0.004680   0.001458     17  \n",
       "6         0.004537   0.001442     17  \n",
       "7         0.004447   0.000838     17  \n",
       "8         0.004372   0.001513     17  \n",
       "9         0.004347   0.000667     17  \n",
       "10        0.004180   0.000637     17  \n",
       "11        0.003947   0.000739     17  \n",
       "12        0.003845   0.000549     17  \n",
       "13        0.003795   0.000689     17  \n",
       "14        0.003738   0.000585     17  \n",
       "15        0.003698   0.000516     17  \n",
       "16        0.003590   0.000572     17  \n",
       "17        0.003311   0.000641     17  \n",
       "18        0.003249   0.000473     17  \n",
       "19        0.003110   0.000448     17  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block B: run perturbation influence across many sequences and aggregate deltas per directed pair\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def aggregate_perturbation_influence(model, pyg_graphs, seq_len, node_names, sample_idxs=None,\n",
    "                                     perturbation=-0.3, which_snapshot=-1, topk_nodes=None):\n",
    "    \"\"\"\n",
    "    For a set of starting indices (sample_idxs), run perturbation on each node individually and measure\n",
    "    average absolute downstream delta on all other nodes. Returns DataFrame with (src, dst, mean_delta, std_delta, occurrences).\n",
    "    If sample_idxs is None, uses many non-overlapping sequences (safe subset) to limit cost.\n",
    "    \"\"\"\n",
    "    n = len(pyg_graphs)\n",
    "    # build valid i such that we can take seq_len snapshots starting at i\n",
    "    valid_starts = [i for i in range(0, n - seq_len)]\n",
    "    if sample_idxs is None:\n",
    "        # sample up to 100 sequences uniformly\n",
    "        sample_idxs = np.linspace(0, len(valid_starts)-1, min(100, len(valid_starts)), dtype=int)\n",
    "        sample_idxs = [valid_starts[int(x)] for x in sample_idxs]\n",
    "    else:\n",
    "        # ensure valid\n",
    "        sample_idxs = [i for i in sample_idxs if i in valid_starts]\n",
    "\n",
    "    influence_store = defaultdict(list)  # key (src_idx,dst_idx) -> list of deltas\n",
    "\n",
    "    model.eval()\n",
    "    for start in tqdm(sample_idxs, desc=\"Perturb samples\"):\n",
    "        seq = [pyg_graphs[j] for j in range(start, start + seq_len)]\n",
    "        # original prediction\n",
    "        with torch.no_grad():\n",
    "            orig = model(seq).cpu().numpy()  # (num_nodes,)\n",
    "        for src_idx in range(len(node_names)):\n",
    "            seq_p = copy.deepcopy(seq)\n",
    "            # perturb all features of src node in chosen snapshot\n",
    "            seq_p[which_snapshot].x[src_idx] = seq_p[which_snapshot].x[src_idx] + perturbation\n",
    "            with torch.no_grad():\n",
    "                pert = model(seq_p).cpu().numpy()\n",
    "            delta = pert - orig  # (num_nodes,) positive indicates increase in predicted mean\n",
    "            for dst_idx in range(len(node_names)):\n",
    "                influence_store[(src_idx, dst_idx)].append(float(delta[dst_idx]))\n",
    "\n",
    "    rows = []\n",
    "    for (src,dst), deltas in influence_store.items():\n",
    "        arr = np.array(deltas)\n",
    "        rows.append({\n",
    "            \"src_idx\": int(src),\n",
    "            \"dst_idx\": int(dst),\n",
    "            \"src\": node_names[src],\n",
    "            \"dst\": node_names[dst],\n",
    "            \"mean_delta\": float(np.mean(arr)),\n",
    "            \"mean_abs_delta\": float(np.mean(np.abs(arr))),\n",
    "            \"std_delta\": float(np.std(arr)),\n",
    "            \"count\": len(arr)\n",
    "        })\n",
    "    df_inf = pd.DataFrame(rows)\n",
    "    # sort by mean_abs_delta descending (strongest influence)\n",
    "    df_inf = df_inf.sort_values(\"mean_abs_delta\", ascending=False).reset_index(drop=True)\n",
    "    return df_inf\n",
    "\n",
    "# Example usage (this can take time depending on sample size):\n",
    "pert_inf_df = aggregate_perturbation_influence(model, pyg_graphs, seq_len, node_names, sample_idxs=None, perturbation=-0.4)\n",
    "pert_inf_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a634a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>src_idx</th>\n",
       "      <th>dst_idx</th>\n",
       "      <th>count</th>\n",
       "      <th>median_weight</th>\n",
       "      <th>median_lag_min</th>\n",
       "      <th>granger_p_median</th>\n",
       "      <th>weights_list</th>\n",
       "      <th>lags_list</th>\n",
       "      <th>pert_mean_abs_delta</th>\n",
       "      <th>abs_med_weight</th>\n",
       "      <th>w_corr_norm</th>\n",
       "      <th>w_pert_norm</th>\n",
       "      <th>score_base</th>\n",
       "      <th>granger_bonus</th>\n",
       "      <th>score</th>\n",
       "      <th>score_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.929256</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.9477135539054871, 0.9017395377159119, 0.952...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, ...</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.929256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546522</td>\n",
       "      <td>0.727913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727913</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.651056</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.7578170299530029, -0.5504528880119324, -0....</td>\n",
       "      <td>[14, 1, 1, 1, 180, 2, 47, 10, 43, 8, 180, 124,...</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.651056</td>\n",
       "      <td>0.443636</td>\n",
       "      <td>0.859133</td>\n",
       "      <td>0.692934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692934</td>\n",
       "      <td>0.944028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.869940</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.9655612707138062, -0.9609084725379944, -0....</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 55, 4, 54, 2, 55, 1, 4, 1, ...</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.869940</td>\n",
       "      <td>0.881375</td>\n",
       "      <td>0.566086</td>\n",
       "      <td>0.692201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692201</td>\n",
       "      <td>0.942854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.715931</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.770922064781189, 0.5661665201187134, 0.7286...</td>\n",
       "      <td>[6, 2, 1, 1, 180, 5, 8, 1, 1, 179, 1, 2, 109, ...</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.715931</td>\n",
       "      <td>0.573378</td>\n",
       "      <td>0.721941</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662516</td>\n",
       "      <td>0.895352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.924469</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.9557874798774719, -0.8696070313453674, -0....</td>\n",
       "      <td>[1, 1, 8, 4, 18, 1, 5, 1, 1, 166, 11, 1, 1, 1,...</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.924469</td>\n",
       "      <td>0.990426</td>\n",
       "      <td>0.431758</td>\n",
       "      <td>0.655225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655225</td>\n",
       "      <td>0.883686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.436273</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.4590439796447754, -0.480249285697937, -0.5...</td>\n",
       "      <td>[60, 5, 2, 6, 6, 6, 6, 25, 7, 172, 128, 3, 4, ...</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.436273</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605640</td>\n",
       "      <td>0.804341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stress_level</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.860379</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.9666393399238586, -0.9603537321090698, -0....</td>\n",
       "      <td>[7, 1, 1, 1, 29, 1, 1, 1, 1, 108, 52, 1, 4, 1,...</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.860379</td>\n",
       "      <td>0.862254</td>\n",
       "      <td>0.404934</td>\n",
       "      <td>0.587862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587862</td>\n",
       "      <td>0.775893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.714787</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.7662836313247681, 0.5766874551773071, 0.767...</td>\n",
       "      <td>[1, 42, 82, 82, 178, 2, 2, 3, 23, 3, 3, 1, 1, ...</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.714787</td>\n",
       "      <td>0.571090</td>\n",
       "      <td>0.536813</td>\n",
       "      <td>0.550524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550524</td>\n",
       "      <td>0.716144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.693467</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.7437114119529724, -0.6740134954452515, -0....</td>\n",
       "      <td>[11, 24, 140, 179, 179, 2, 2, 2, 18, 2, 180, 2...</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.528453</td>\n",
       "      <td>0.525934</td>\n",
       "      <td>0.526941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526941</td>\n",
       "      <td>0.678409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.533685</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.5521436929702759, -0.5932676792144775, -0....</td>\n",
       "      <td>[48, 6, 5, 1, 2, 2, 8, 21, 5, 3, 1, 1, 12, 3, ...</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.533685</td>\n",
       "      <td>0.208911</td>\n",
       "      <td>0.662309</td>\n",
       "      <td>0.480950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480950</td>\n",
       "      <td>0.604814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.537711</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.5441463589668274, -0.588294267654419, -0.6...</td>\n",
       "      <td>[9, 2, 2, 2, 28, 28, 8, 2, 9, 69, 2, 9, 9, 2, ...</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.537711</td>\n",
       "      <td>0.216961</td>\n",
       "      <td>0.647773</td>\n",
       "      <td>0.475448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475448</td>\n",
       "      <td>0.596011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>stress_level</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.492210</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.5351166725158691, 0.5710274577140808, 0.652...</td>\n",
       "      <td>[5, 3, 3, 1, 9, 9, 4, 1, 3, 3, 9, 1, 32, 16, 1...</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.492210</td>\n",
       "      <td>0.125966</td>\n",
       "      <td>0.707182</td>\n",
       "      <td>0.474696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474696</td>\n",
       "      <td>0.594806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stress_level</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.758777379989624, -0.5738000869750977, -0.7...</td>\n",
       "      <td>[19, 58, 124, 124, 4, 18, 1, 1, 1, 179, 1, 1, ...</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.644204</td>\n",
       "      <td>0.429934</td>\n",
       "      <td>0.497381</td>\n",
       "      <td>0.470402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470402</td>\n",
       "      <td>0.587936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.528713</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.5473551750183105, 0.608403742313385, 0.6587...</td>\n",
       "      <td>[51, 1, 39, 1, 37, 1, 1, 1, 1, 1, 1, 1, 20, 1,...</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.528713</td>\n",
       "      <td>0.198967</td>\n",
       "      <td>0.643075</td>\n",
       "      <td>0.465432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465432</td>\n",
       "      <td>0.579982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stress_level</td>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.491644</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.5497491955757141, 0.5741972327232361, 0.656...</td>\n",
       "      <td>[39, 4, 4, 4, 37, 2, 2, 2, 2, 2, 2, 2, 23, 2, ...</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.491644</td>\n",
       "      <td>0.124834</td>\n",
       "      <td>0.610945</td>\n",
       "      <td>0.416501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416501</td>\n",
       "      <td>0.501684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.429223</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.4447994530200958, -0.4811718761920929, -0....</td>\n",
       "      <td>[16, 22, 44, 112, 4, 31, 10, 10, 18, 164, 4, 7...</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.429223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679652</td>\n",
       "      <td>0.407791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407791</td>\n",
       "      <td>0.487747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sleep_quality</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.927903</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.9545643925666809, -0.8698533773422241, -0....</td>\n",
       "      <td>[4, 1, 1, 1, 1, 1, 24, 2, 23, 7, 178, 18, 1, 1...</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.927903</td>\n",
       "      <td>0.997294</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.404474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404474</td>\n",
       "      <td>0.482438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stress_level</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.928015</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.9487643241882324, 0.9015536308288574, 0.952...</td>\n",
       "      <td>[8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, ...</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.928015</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399007</td>\n",
       "      <td>0.473691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cardio_stability</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.696417</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.7451180219650269, -0.6690930724143982, -0....</td>\n",
       "      <td>[4, 1, 1, 1, 179, 1, 9, 2, 9, 1, 180, 179, 114...</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.696417</td>\n",
       "      <td>0.534353</td>\n",
       "      <td>0.069125</td>\n",
       "      <td>0.255217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255217</td>\n",
       "      <td>0.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pulmonary_efficiency</td>\n",
       "      <td>cognitive_load</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.535893</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.5358934998512268, 0.6042319536209106, 0.645...</td>\n",
       "      <td>[11, 10, 11, 5, 10, 3, 2, 2, 4, 2, 7, 7, 7, 7,...</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.535893</td>\n",
       "      <td>0.213327</td>\n",
       "      <td>0.029421</td>\n",
       "      <td>0.102984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102984</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     src                   dst  src_idx  dst_idx  count  \\\n",
       "0         cognitive_load          stress_level        4        1     23   \n",
       "1       cardio_stability          stress_level        2        1     23   \n",
       "2          sleep_quality          stress_level        0        1     23   \n",
       "3       cardio_stability         sleep_quality        2        0     23   \n",
       "4         cognitive_load         sleep_quality        4        0     22   \n",
       "5       cardio_stability  pulmonary_efficiency        2        3     17   \n",
       "6           stress_level         sleep_quality        1        0     23   \n",
       "7          sleep_quality      cardio_stability        0        2     23   \n",
       "8         cognitive_load      cardio_stability        4        2     23   \n",
       "9          sleep_quality  pulmonary_efficiency        0        3     17   \n",
       "10  pulmonary_efficiency         sleep_quality        3        0     16   \n",
       "11  pulmonary_efficiency          stress_level        3        1     21   \n",
       "12          stress_level      cardio_stability        1        2     22   \n",
       "13        cognitive_load  pulmonary_efficiency        4        3     21   \n",
       "14          stress_level  pulmonary_efficiency        1        3     21   \n",
       "15  pulmonary_efficiency      cardio_stability        3        2     16   \n",
       "16         sleep_quality        cognitive_load        0        4     22   \n",
       "17          stress_level        cognitive_load        1        4     23   \n",
       "18      cardio_stability        cognitive_load        2        4     23   \n",
       "19  pulmonary_efficiency        cognitive_load        3        4     19   \n",
       "\n",
       "    median_weight  median_lag_min  granger_p_median  \\\n",
       "0        0.929256               1               NaN   \n",
       "1       -0.651056              19               NaN   \n",
       "2       -0.869940               1               NaN   \n",
       "3        0.715931               3               NaN   \n",
       "4       -0.924469               1               NaN   \n",
       "5       -0.436273               6               NaN   \n",
       "6       -0.860379               1               NaN   \n",
       "7        0.714787               3               NaN   \n",
       "8       -0.693467               3               NaN   \n",
       "9       -0.533685               5               NaN   \n",
       "10      -0.537711               5               NaN   \n",
       "11       0.492210               3               NaN   \n",
       "12      -0.644204               4               NaN   \n",
       "13       0.528713               1               NaN   \n",
       "14       0.491644               4               NaN   \n",
       "15      -0.429223              17               NaN   \n",
       "16      -0.927903               3               NaN   \n",
       "17       0.928015               1               NaN   \n",
       "18      -0.696417               9               NaN   \n",
       "19       0.535893               7               NaN   \n",
       "\n",
       "                                         weights_list  \\\n",
       "0   [0.9477135539054871, 0.9017395377159119, 0.952...   \n",
       "1   [-0.7578170299530029, -0.5504528880119324, -0....   \n",
       "2   [-0.9655612707138062, -0.9609084725379944, -0....   \n",
       "3   [0.770922064781189, 0.5661665201187134, 0.7286...   \n",
       "4   [-0.9557874798774719, -0.8696070313453674, -0....   \n",
       "5   [-0.4590439796447754, -0.480249285697937, -0.5...   \n",
       "6   [-0.9666393399238586, -0.9603537321090698, -0....   \n",
       "7   [0.7662836313247681, 0.5766874551773071, 0.767...   \n",
       "8   [-0.7437114119529724, -0.6740134954452515, -0....   \n",
       "9   [-0.5521436929702759, -0.5932676792144775, -0....   \n",
       "10  [-0.5441463589668274, -0.588294267654419, -0.6...   \n",
       "11  [0.5351166725158691, 0.5710274577140808, 0.652...   \n",
       "12  [-0.758777379989624, -0.5738000869750977, -0.7...   \n",
       "13  [0.5473551750183105, 0.608403742313385, 0.6587...   \n",
       "14  [0.5497491955757141, 0.5741972327232361, 0.656...   \n",
       "15  [-0.4447994530200958, -0.4811718761920929, -0....   \n",
       "16  [-0.9545643925666809, -0.8698533773422241, -0....   \n",
       "17  [0.9487643241882324, 0.9015536308288574, 0.952...   \n",
       "18  [-0.7451180219650269, -0.6690930724143982, -0....   \n",
       "19  [0.5358934998512268, 0.6042319536209106, 0.645...   \n",
       "\n",
       "                                            lags_list  pert_mean_abs_delta  \\\n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, ...             0.003845   \n",
       "1   [14, 1, 1, 1, 180, 2, 47, 10, 43, 8, 180, 124,...             0.005470   \n",
       "2   [1, 1, 1, 1, 1, 1, 55, 4, 54, 2, 55, 1, 4, 1, ...             0.003947   \n",
       "3   [6, 2, 1, 1, 180, 5, 8, 1, 1, 179, 1, 2, 109, ...             0.004757   \n",
       "4   [1, 1, 8, 4, 18, 1, 5, 1, 1, 166, 11, 1, 1, 1,...             0.003249   \n",
       "5   [60, 5, 2, 6, 6, 6, 6, 25, 7, 172, 128, 3, 4, ...             0.006202   \n",
       "6   [7, 1, 1, 1, 29, 1, 1, 1, 1, 108, 52, 1, 4, 1,...             0.003110   \n",
       "7   [1, 42, 82, 82, 178, 2, 2, 3, 23, 3, 3, 1, 1, ...             0.003795   \n",
       "8   [11, 24, 140, 179, 179, 2, 2, 2, 18, 2, 180, 2...             0.003738   \n",
       "9   [48, 6, 5, 1, 2, 2, 8, 21, 5, 3, 1, 1, 12, 3, ...             0.004447   \n",
       "10  [9, 2, 2, 2, 28, 28, 8, 2, 9, 69, 2, 9, 9, 2, ...             0.004372   \n",
       "11  [5, 3, 3, 1, 9, 9, 4, 1, 3, 3, 9, 1, 32, 16, 1...             0.004680   \n",
       "12  [19, 58, 124, 124, 4, 18, 1, 1, 1, 179, 1, 1, ...             0.003590   \n",
       "13  [51, 1, 39, 1, 37, 1, 1, 1, 1, 1, 1, 1, 20, 1,...             0.004347   \n",
       "14  [39, 4, 4, 4, 37, 2, 2, 2, 2, 2, 2, 2, 23, 2, ...             0.004180   \n",
       "15  [16, 22, 44, 112, 4, 31, 10, 10, 18, 164, 4, 7...             0.004537   \n",
       "16  [4, 1, 1, 1, 1, 1, 24, 2, 23, 7, 178, 18, 1, 1...             0.001054   \n",
       "17  [8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, ...             0.001006   \n",
       "18  [4, 1, 1, 1, 179, 1, 9, 2, 9, 1, 180, 179, 114...             0.001365   \n",
       "19  [11, 10, 11, 5, 10, 3, 2, 2, 4, 2, 7, 7, 7, 7,...             0.001159   \n",
       "\n",
       "    abs_med_weight  w_corr_norm  w_pert_norm  score_base  granger_bonus  \\\n",
       "0         0.929256     1.000000     0.546522    0.727913            0.0   \n",
       "1         0.651056     0.443636     0.859133    0.692934            0.0   \n",
       "2         0.869940     0.881375     0.566086    0.692201            0.0   \n",
       "3         0.715931     0.573378     0.721941    0.662516            0.0   \n",
       "4         0.924469     0.990426     0.431758    0.655225            0.0   \n",
       "5         0.436273     0.014100     1.000000    0.605640            0.0   \n",
       "6         0.860379     0.862254     0.404934    0.587862            0.0   \n",
       "7         0.714787     0.571090     0.536813    0.550524            0.0   \n",
       "8         0.693467     0.528453     0.525934    0.526941            0.0   \n",
       "9         0.533685     0.208911     0.662309    0.480950            0.0   \n",
       "10        0.537711     0.216961     0.647773    0.475448            0.0   \n",
       "11        0.492210     0.125966     0.707182    0.474696            0.0   \n",
       "12        0.644204     0.429934     0.497381    0.470402            0.0   \n",
       "13        0.528713     0.198967     0.643075    0.465432            0.0   \n",
       "14        0.491644     0.124834     0.610945    0.416501            0.0   \n",
       "15        0.429223     0.000000     0.679652    0.407791            0.0   \n",
       "16        0.927903     0.997294     0.009260    0.404474            0.0   \n",
       "17        0.928015     0.997518     0.000000    0.399007            0.0   \n",
       "18        0.696417     0.534353     0.069125    0.255217            0.0   \n",
       "19        0.535893     0.213327     0.029421    0.102984            0.0   \n",
       "\n",
       "       score  score_norm  \n",
       "0   0.727913    1.000000  \n",
       "1   0.692934    0.944028  \n",
       "2   0.692201    0.942854  \n",
       "3   0.662516    0.895352  \n",
       "4   0.655225    0.883686  \n",
       "5   0.605640    0.804341  \n",
       "6   0.587862    0.775893  \n",
       "7   0.550524    0.716144  \n",
       "8   0.526941    0.678409  \n",
       "9   0.480950    0.604814  \n",
       "10  0.475448    0.596011  \n",
       "11  0.474696    0.594806  \n",
       "12  0.470402    0.587936  \n",
       "13  0.465432    0.579982  \n",
       "14  0.416501    0.501684  \n",
       "15  0.407791    0.487747  \n",
       "16  0.404474    0.482438  \n",
       "17  0.399007    0.473691  \n",
       "18  0.255217    0.243600  \n",
       "19  0.102984    0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block C: merge correlation/granger evidence with perturbation evidence into a single edge score\n",
    "def combine_edge_evidence(global_edges_df, pert_inf_df, node_names,\n",
    "                          w_corr=0.5, w_pert=0.5, granger_boost=0.15):\n",
    "    \"\"\"\n",
    "    Creates unified confidence per directed edge using:\n",
    "      score = w_corr * normalized(|median_weight|) + w_pert * normalized(mean_abs_delta)\n",
    "    If granger p-value exists and < 0.05, add granger_boost to score.\n",
    "    Normalization is done across all edges to [0,1].\n",
    "    Returns DataFrame with src,dst,median_lag,score and components.\n",
    "    \"\"\"\n",
    "    # prepare perturbation lookup\n",
    "    pert_map = {(r.src_idx, r.dst_idx): r for _, r in pert_inf_df.iterrows()} if not pert_inf_df.empty else {}\n",
    "    # take copies\n",
    "    ged = global_edges_df.copy()\n",
    "    # map pert values\n",
    "    pert_vals = []\n",
    "    for _, row in ged.iterrows():\n",
    "        key = (row.src_idx, row.dst_idx)\n",
    "        if key in pert_map:\n",
    "            pert_vals.append(pert_map[key][\"mean_abs_delta\"])\n",
    "        else:\n",
    "            pert_vals.append(0.0)\n",
    "    ged[\"pert_mean_abs_delta\"] = pert_vals\n",
    "\n",
    "    # normalize median_weight absolute and pert\n",
    "    def normalize_series(s):\n",
    "        if s.max() == s.min():\n",
    "            return np.zeros_like(s, dtype=float)\n",
    "        return (s - s.min()) / (s.max() - s.min())\n",
    "\n",
    "    ged[\"abs_med_weight\"] = np.abs(ged[\"median_weight\"])\n",
    "    ged[\"w_corr_norm\"] = normalize_series(ged[\"abs_med_weight\"])\n",
    "    ged[\"w_pert_norm\"] = normalize_series(ged[\"pert_mean_abs_delta\"])\n",
    "    ged[\"score_base\"] = w_corr * ged[\"w_corr_norm\"] + w_pert * ged[\"w_pert_norm\"]\n",
    "    # granger boost if present and low p\n",
    "    def granger_bonus(p):\n",
    "        if np.isnan(p): return 0.0\n",
    "        return granger_boost if p < 0.05 else 0.0\n",
    "    ged[\"granger_bonus\"] = ged[\"granger_p_median\"].apply(granger_bonus)\n",
    "    ged[\"score\"] = ged[\"score_base\"] + ged[\"granger_bonus\"]\n",
    "    # final normalization to [0,1]\n",
    "    ged[\"score_norm\"] = normalize_series(ged[\"score\"])\n",
    "    # sort\n",
    "    ged = ged.sort_values(\"score_norm\", ascending=False).reset_index(drop=True)\n",
    "    return ged\n",
    "\n",
    "# Example usage:\n",
    "combined_edges_df = combine_edge_evidence(global_edges_df, pert_inf_df, node_names,\n",
    "                                          w_corr=0.4, w_pert=0.6, granger_boost=0.15)\n",
    "combined_edges_df.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85e1edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep_quality -> stress_level | total_lag=1min | score=0.943\n",
      "    sleep_quality -> stress_level lag=1 score=0.943\n",
      "\n",
      "sleep_quality -> stress_level -> sleep_quality | total_lag=2min | score=0.732\n",
      "    sleep_quality -> stress_level lag=1 score=0.943\n",
      "    stress_level -> sleep_quality lag=1 score=0.776\n",
      "\n",
      "sleep_quality -> cardio_stability | total_lag=3min | score=0.716\n",
      "    sleep_quality -> cardio_stability lag=3 score=0.716\n",
      "\n",
      "sleep_quality -> stress_level -> sleep_quality -> stress_level | total_lag=3min | score=0.690\n",
      "    sleep_quality -> stress_level lag=1 score=0.943\n",
      "    stress_level -> sleep_quality lag=1 score=0.776\n",
      "    sleep_quality -> stress_level lag=1 score=0.943\n",
      "\n",
      "sleep_quality -> cardio_stability -> stress_level | total_lag=22min | score=0.676\n",
      "    sleep_quality -> cardio_stability lag=3 score=0.716\n",
      "    cardio_stability -> stress_level lag=19 score=0.944\n",
      "\n",
      "sleep_quality -> cardio_stability -> sleep_quality | total_lag=6min | score=0.641\n",
      "    sleep_quality -> cardio_stability lag=3 score=0.716\n",
      "    cardio_stability -> sleep_quality lag=3 score=0.895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Block D: extract causal chains starting from a seed node using combined edge table\n",
    "from heapq import heappush, heappop\n",
    "\n",
    "def build_adj_from_combined(combined_edges_df, score_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Build adjacency dict: src_idx -> list of (dst_idx, median_lag, score_norm)\n",
    "    Only include edges with score_norm >= score_threshold\n",
    "    \"\"\"\n",
    "    adj = defaultdict(list)\n",
    "    for _, r in combined_edges_df.iterrows():\n",
    "        if r.score_norm < score_threshold:\n",
    "            continue\n",
    "        adj[int(r.src_idx)].append((int(r.dst_idx), int(r.median_lag_min), float(r.score_norm)))\n",
    "    return adj\n",
    "\n",
    "def extract_top_chains(adj, seed_idx, node_names, max_hops=4, top_k=5, min_confidence=0.05):\n",
    "    \"\"\"\n",
    "    Greedy best-first search to extract top_k causal chains from seed node.\n",
    "    Score of chain = product of (edge_score) (interpreted as joint confidence), or you can sum logs.\n",
    "    Returns list of chains: each is dict {path: [names], hops, total_lag_min, chain_score, edges: [(src,dst,lag,score)...]}\n",
    "    \"\"\"\n",
    "    # priority queue by -score so higher score first\n",
    "    pq = []\n",
    "    # initialize with seed\n",
    "    heappush(pq, (-1.0, 0, seed_idx, [], 0))  # (neg_score, hops, current_node, path_edges, total_lag)\n",
    "    results = []\n",
    "    seen_paths = set()\n",
    "    while pq and len(results) < top_k:\n",
    "        neg_score, hops, cur, path_edges, total_lag = heappop(pq)\n",
    "        score = -neg_score\n",
    "        # if not initial node, generate a readable path\n",
    "        if path_edges:\n",
    "            path_nodes = [node_names[path_edges[0][0]]] + [node_names[e[1]] for e in path_edges]\n",
    "            path_tuple = tuple(path_nodes)\n",
    "            if path_tuple in seen_paths:\n",
    "                continue\n",
    "            seen_paths.add(path_tuple)\n",
    "            results.append({\n",
    "                \"path\": path_nodes,\n",
    "                \"hops\": hops,\n",
    "                \"total_lag_min\": total_lag,\n",
    "                \"chain_score\": score,\n",
    "                \"edges\": [{\"src_idx\": e[0], \"dst_idx\": e[1], \"lag_min\": e[2], \"edge_score\": e[3]} for e in path_edges]\n",
    "            })\n",
    "        if hops >= max_hops:\n",
    "            continue\n",
    "        # explore next edges\n",
    "        for (dst, lag, escore) in adj.get(cur, []):\n",
    "            new_score = score * escore  # multiplicative confidence\n",
    "            if new_score < min_confidence:\n",
    "                continue\n",
    "            new_edges = path_edges + [(cur, dst, lag, escore)]\n",
    "            heappush(pq, (-new_score, hops+1, dst, new_edges, total_lag + lag))\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "adj = build_adj_from_combined(combined_edges_df, score_threshold=0.05)\n",
    "seed = node_names.index(\"sleep_quality\") if \"sleep_quality\" in node_names else 0\n",
    "chains = extract_top_chains(adj, seed, node_names, max_hops=4, top_k=6, min_confidence=0.02)\n",
    "for c in chains:\n",
    "    print(\" -> \".join(c[\"path\"]), f\"| total_lag={c['total_lag_min']}min | score={c['chain_score']:.3f}\")\n",
    "    for e in c[\"edges\"]:\n",
    "        print(\"   \", f\"{node_names[e['src_idx']]} -> {node_names[e['dst_idx']]} lag={e['lag_min']} score={e['edge_score']:.3f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88bdb058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain (total ~1 min, score=0.943): sleep_quality → stress_level (after ~1 min, confidence 0.94)\n",
      "Chain (total ~2 min, score=0.732): sleep_quality → stress_level (after ~1 min, confidence 0.94)  then  stress_level → sleep_quality (after ~1 min, confidence 0.78)\n",
      "Chain (total ~3 min, score=0.716): sleep_quality → cardio_stability (after ~3 min, confidence 0.72)\n",
      "Chain (total ~3 min, score=0.690): sleep_quality → stress_level (after ~1 min, confidence 0.94)  then  stress_level → sleep_quality (after ~1 min, confidence 0.78)  then  sleep_quality → stress_level (after ~1 min, confidence 0.94)\n",
      "Chain (total ~22 min, score=0.676): sleep_quality → cardio_stability (after ~3 min, confidence 0.72)  then  cardio_stability → stress_level (after ~19 min, confidence 0.94)\n",
      "Chain (total ~6 min, score=0.641): sleep_quality → cardio_stability (after ~3 min, confidence 0.72)  then  cardio_stability → sleep_quality (after ~3 min, confidence 0.90)\n"
     ]
    }
   ],
   "source": [
    "# Block E: generate human-friendly timeline narratives from extracted chains\n",
    "def narrative_from_chain(chain):\n",
    "    \"\"\"\n",
    "    chain: one element from extract_top_chains output\n",
    "    returns a short human-readable timeline string.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    cum_lag = 0\n",
    "    for i, e in enumerate(chain[\"edges\"]):\n",
    "        src = node_names[e[\"src_idx\"]]\n",
    "        dst = node_names[e[\"dst_idx\"]]\n",
    "        lag = e[\"lag_min\"]\n",
    "        esc = e[\"edge_score\"]\n",
    "        cum_lag += lag\n",
    "        parts.append(f\"{src} → {dst} (after ~{lag} min, confidence {esc:.2f})\")\n",
    "    timeline = \"  then  \".join(parts)\n",
    "    return f\"Chain (total ~{chain['total_lag_min']} min, score={chain['chain_score']:.3f}): {timeline}\"\n",
    "\n",
    "# Example: print narratives for the discovered chains\n",
    "for c in chains:\n",
    "    print(narrative_from_chain(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3019117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AllPackages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
